# Training Pipeline

This guide outlines the complete pipeline for training the RSMT (Real-time Stylized Motion Transition for Characters) model. The training process consists of multiple stages that must be executed in sequence.

## Overview of the Training Pipeline

The RSMT training pipeline consists of four main stages:

1. **Dataset Preprocessing**: Convert BVH files to binary format and prepare the data
2. **Phase Manifold Training**: Train the DeepPhase model to learn temporal motion encoding
3. **Manifold Training**: Train the StyleVAE to learn spatial motion encoding
4. **Sampler Training**: Train the final transition model to generate stylized motion transitions

## Prerequisites

Before beginning the training process, ensure:
- You have completed the [Installation](installation.md) steps
- The dataset is properly prepared as described in [Dataset Preparation](dataset_preparation.md)

## Stage 1: Train Phase Model

The Phase Manifold learns to encode the temporal aspects of motion into a 2D phase space.

1. Prepare the dataset for phase training:
   ```bash
   python process_dataset.py --train_phase_model
   ```

2. Train the DeepPhase model:
   ```bash
   python train_deephase.py
   ```

3. Validate the trained model:
   ```bash
   python train_deephase.py --test --version YOUR_VERSION --epoch YOUR_EPOCH
   ```
   Replace `YOUR_VERSION` with the actual version number (directory in results) and `YOUR_EPOCH` with the epoch number to test.

   This will generate two figures:
   - phase.png: Visualization of the learned phase manifold
   - SAFB.png: Self-adaptive frequency bands

## Stage 2: Generate Phase Vectors for the Dataset

After training the phase model, you need to generate phase vectors for all motion sequences in the dataset:

```bash
python process_dataset.py --add_phase_to_dataset --model_path "YOUR_PHASE_MODEL_PATH"
```

Replace `YOUR_PHASE_MODEL_PATH` with the path to your trained phase model (e.g., `./results/deephase_sty/myResults/31/epoch=161-step=383778-v1.ckpt`).

## Stage 3: Train Manifold (StyleVAE)

The Manifold component learns to encode and decode motion content in a latent space:

1. Prepare the dataset for manifold training (splitting sequences into 60-frame windows):
   ```bash
   python process_dataset.py --train_manifold_model
   ```

2. Train the StyleVAE model:
   ```bash
   python train_styleVAE.py
   ```

3. Validate the trained model:
   ```bash
   python train_styleVAE.py --test --version YOUR_VERSION --epoch YOUR_EPOCH
   ```
   Replace `YOUR_VERSION` and `YOUR_EPOCH` with the appropriate values.

   This will generate multiple BVH files, with `test_net.bvh` being generated by the trained model. The model will be saved as `m_save_model_YOUR_EPOCH`.

## Stage 4: Train Sampler

The Sampler is the final component that generates transitions between motions:

1. Prepare the dataset for sampler training (note that style sequences contain 120 frames per sequence):
   ```bash
   python process_dataset.py --train_sampler_model
   ```

2. Train the Sampler using the trained Manifold model:
   ```bash
   python train_transitionNet.py --moe_model YOUR_MANIFOLD_MODEL
   ```
   Replace `YOUR_MANIFOLD_MODEL` with the path to the trained manifold model (e.g., `m_save_model_198`).

3. Validate the trained model:
   ```bash
   python train_transitionNet.py --test --moe_model YOUR_MANIFOLD_MODEL --version YOUR_VERSION --epoch YOUR_EPOCH
   ```

   The output result will be `test_net.bvh`.

## Advanced Training: Phase Predictor

For applications requiring phase prediction without corresponding phase vectors:

```bash
python train_transitionNet.py --moe_model YOUR_MANIFOLD_MODEL --predict_phase --pretrained --version YOUR_VERSION --epoch YOUR_EPOCH
```

## Training Parameters and Customization

Each training script accepts various parameters that can be used to customize the training process:

- `--dev_run`: Run a quick development run for testing
- `--version`: Specify a version number for the training run
- `--resume`: Resume training from a checkpoint
- `--epoch`: Specify which epoch to load for testing or resuming

For a complete list of parameters, check the argument parser in each training script.

## Monitoring Training

Training progress is logged using PyTorch Lightning's TensorBoard logger. To monitor training:

1. Install TensorBoard if not already installed:
   ```bash
   pip install tensorboard
   ```

2. Launch TensorBoard:
   ```bash
   tensorboard --logdir=tensorboard_logs/
   ```

3. Open your browser at [http://localhost:6006](http://localhost:6006) to view the training metrics.

## Training Results

The training results are stored in the `results/` directory, organized by model type and version. Each version contains checkpoints saved during training.

## Next Steps

After completing the training pipeline, follow the [Inference Guide](inference_guide.md) to generate stylized motion transitions using your trained model.
